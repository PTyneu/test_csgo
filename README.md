# test_csgo

В репозитории решение тестовго задания DataLouna (ноутбук для наглядности, таблички в нем делать удобнее). Использовал две базовые модели (логрег и метод опорных веткоров), результаты на кросс-валидации отвратительные, на тесте будет примерно тоже +-5%, посмотрел, что выдаст катбуст, среднее по кросс-валидации 55%, даже с затюненными параметрами он сильно выше не уйдет, лгбм и иксджи выдают результаты из того же диапазона, соответственно блендинг применять особого смысла нет. Поэтому выбор - автомл (в него вшит перцептрон, поэтому особого смысла написания полносвязной сетки тоже не вижу). Сабмита два - для метода опорных векторов (sub_svm) и автомл (sub_automl), по-хорошему нужно было произвести оценку важности фичей (добавить просто шум к примеру и все что ниже него по важности для моделей выкинуть), как это напрмер частично сделано здесь https://github.com/PTyneu/Raif/blob/main/Raif_finale.py, поиграть с апсемплингом, тк 700 примеров маловато для обучения более сложных моделей, но я героически потратил 2.5 дня на то, чтобы сконкатить таблицы (игрушка дьявола), а решение этой проблемы меня убило, но зато сам до этого дошел, тоже ничего. В любом случае спасибо за возможность подумать хотя бы о кс как о своей работе аххаахах, если дадите шанс пройти собес - спасибо, если нет, то справедливо, рок-кривая там будет потолок 0,6-0,7 без работы с фичами даже если я авто мл до утра крутить поставлю. (:
![repcs](https://user-images.githubusercontent.com/90149954/205514960-ae9fd1ab-2701-4a23-bd50-835aca5903a3.jpg)
